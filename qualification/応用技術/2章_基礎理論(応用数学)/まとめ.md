## 情報量
- 情報量
  - ある出来事に対して、それがどれくらい起こりにくいかを表す尺度のこと。
  - 起こりにくいものほど、その事象が持つ情報量は大きいと考えることができる。
- 情報量の定義
  - 情報量 = -log2P[ビット]
  - 例
    - サイコロで5の目が出たという情報は
      - -log2 1/6 = -log2 6^-1 = 2.58ビット
    - コインの裏か表かを表す情報量は
      - -log2 1/2 = -log2 2^-1 = 1ビット
  - 起こりにくいものほど事象の持つ要素の数は多い。その要素の数が何ビットで表されるかとも見ることができる。
- 平均情報量(エントロピー)
  - Σ(事象が発生する確率 × 情報量)

## 符号化
- 符号化
  - 情報を2進数のデジタルデータに変換するのが符号化
- ハフマン符号化
  - データの出現頻度に着目した圧縮方法
  - 出現頻度の高いデータに短いbitを割り当て、出現頻度の低いデータには長いbit列を与える。これにより、1データあたりの平均ビット長を小さくする。
    - -log2Pで表されるため、P(確率)は小さいほどビット長は長くなる。
- ハフマン図
  - p.100参照
  - 各要素のパーセントを低い順に並べる。
  - 最も低いもの同士を足したものを親として、左側を1、右側を0とする。
  - 足したものが100になるまで繰り返す。
  - ビットの数と出現確率をかけたものの総和が期待値となる。
